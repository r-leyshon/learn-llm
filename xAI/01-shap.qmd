---
title: Understanding `shap`
subtitle: SHapley Additive exPlanations
---

```{python}
from pyprojroot import here
import pandas as pd
from sklearn.metrics import classification_report
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import shap
shap.initjs()
```


Data from [Kaggle](https://www.kaggle.com/datasets/royjafari/customer-churn?resource=download), requires a free account.

```{python}
churn = pd.read_csv(here("data/xAI/churn.csv"))
churn.head()

```


```{python}
X = churn.drop("Churn", axis=1)
y = churn.Churn
# Split train & test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)
# Train random forest
clf = RandomForestClassifier()
clf.fit(X_train, y_train)
# Predict on the testing data
y_pred = clf.predict(X_test)
# report metrics
print(classification_report(y_pred, y_test))
```

```{python}
explainer = shap.Explainer(clf)
shap_values = explainer.shap_values(X_test)

```

## Summary Plot

Useful for giving a global indication of feature importance across all records used for the model.

```{python}
shap.summary_plot(shap_values, X_test)
```

summary plot for 0 label only
```{python}
# shap.summary_plot(shap_values[0], X_test)

```


## Dependence Plot

Explore how a model's predictions are affected by a specific feature.

```{python}
# shap.dependence_plot("Subscription  Length", shap_values[0], X_test,interaction_index="Age")

```

## Force Plot

Examine feature importance for a single record's prediction.


```{python}
# shap.plots.force(explainer.expected_value[0], shap_values[0][0,:], X_test.iloc[0, :], matplotlib = True)

```

## Decision Plot

Plots cumulative SHAP values across all dimensions for a specified outcome class. This indicates which features influenced the outcome.

```{python}
# shap.decision_plot(explainer.expected_value[1], shap_values[1], X_test.columns)
```